Q.2_Build_a_multi_layer_perceptron_for_a_classification_problem_Experiment_with_different_activation_functions_and_layer_configurations.ipynb
A#For Iris Dataset
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report, confusion_matrix
# Load the Iris dataset
iris = load_iris()
X = iris.data  # shape: (150, 4)
y = iris.target  # shape: (150,)

# Normalize the dataset
scaler = StandardScaler()
X = scaler.fit_transform(X)

# One hot encode the labels
y = to_categorical(y, num_classes=3)

# Split into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Build MLP model function
def build_mlp(activation='relu', layer_config=[64, 32]):
    model = Sequential()
    model.add(Dense(layer_config[0], input_shape=(4,), activation=activation))
    for units in layer_config[1:]:
        model.add(Dense(units, activation=activation))
    model.add(Dense(3, activation='softmax'))  # 3 classes for Iris
    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])
    return model
# Experiment with different configurations
activations = ['relu', 'tanh', 'sigmoid']
layer_configs = [[64, 32], [128, 64, 32], [256, 128, 64, 32]]

results = {}

for activation in activations:
    for config in layer_configs:
        model = build_mlp(activation=activation, layer_config=config)
        history = model.fit(X_train, y_train, epochs=50, batch_size=8, validation_split=0.2, verbose=0)
        _, accuracy = model.evaluate(X_test, y_test, verbose=0)
        results[(activation, tuple(config))] = accuracy
        print(f'Activation: {activation}, Layer Config: {config}, Accuracy: {accuracy:.4f}')
# Visualize results
plt.figure(figsize=(12, 6))
for key, value in results.items():
    plt.bar(str(key), value)
plt.xticks(rotation=90)
plt.xlabel('Activation and layer configuration')
plt.ylabel('Accuracy')
plt.title('Accuracy for Different Activation Functions and Layer Configurations (Iris Dataset)')
plt.tight_layout()
plt.show()

# Classification report for the best model
best_model_key = max(results, key=results.get)
best_activation, best_config = best_model_key
best_model = build_mlp(activation=best_activation, layer_config=list(best_config))
best_model.fit(X_train, y_train, epochs=50, batch_size=8, validation_split=0.2, verbose=0)

y_pred = np.argmax(best_model.predict(X_test), axis=-1)
y_test_labels = np.argmax(y_test, axis=-1)

print("\nClassification Report:\n")
print(classification_report(y_test_labels, y_pred, target_names=iris.target_names))


#For MNIST Dataset
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report, confusion_matrix
#Load the MNIST Dataset
(X_train, y_train), (X_test, y_test) = mnist.load_data()
#Normalize the dataset (INPUT)
X_train = X_train.astype('float32') / 255.0 #(255 - image scale ,gray scale)
X_test = X_test.astype('float32') / 255.0
#One hot encode the labels (OUTPUT)
y_train = to_categorical(y_train, num_classes=10) # Converting Class labels into one hot encode format
y_test = to_categorical(y_test, num_classes=10)
#Build a Multi-layer Perceptron model
def build_mlp(activation = 'relu', layer_config=[128,64]): #2 layer
    model = Sequential() # Method or function to create a squential network
    model.add(Flatten(input_shape=(28,28)))
    for units in layer_config:
        model.add(Dense(units, activation=activation))
    model.add(Dense(10, activation='softmax')) # softmax- individual to probabilities
    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])
    return model
#Experiment with different configurations
activation = ['relu','tanh','sigmoid']
layer_configs = [[128,64],[256,128,64],[512,256,128,64]]

results ={}
for activation in activation:
    for config in layer_configs:
        model = build_mlp(activation=activation, layer_config = config)
        history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=0)
        _, accuracy = model.evaluate(X_test, y_test, verbose=0)
        results[(activation, tuple(config))] = accuracy
        print(f'Activation: {activation}, Layer Config: {config}, Accuracy: {accuracy:.4f}')
#Visualize the results
plt.figure(figsize=(12,8))
for key,value in results.items():
    plt.bar(str(key), value)
plt.xticks(rotation=90)
plt.xlabel('Activation and layer configuration')
plt.ylabel('Accuracy')
plt.title('Accuracy for Differnent activation function and layer configurations')
plt.show()

#Display classification report for the best model
best_model_key = max(results, key=results.get)
best_activation, best_config = best_model_key
best_model = build_mlp(activation=best_activation, layer_config=best_config)
best_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=0)
y_pred = np.argmax(best_model.predict(X_test), axis=-1)
y_test_labels = np.argmax(y_test, axis=-1)

#Display some test image with their predicated labels
plt.figure(figsize=(15,15))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.imshow(X_test[i], cmap='gray')
    plt.title(f'Predicted: {y_pred[i]}, True: {y_test_labels[i]}')
    plt.axis('off')
plt.show()
Q.33_Create_a_CNN_for_image_classification_using_a_popular_dataset_like_MNIST_or_CIFAR_10_.ipynb
# Import required libraries
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow import keras
from tensorflow.keras import layers, models
from sklearn.metrics import classification_report, confusion_matrix
# 1. Dataset Preparation
# ----------------------

# Load the MNIST dataset (28x28 grayscale images of handwritten digits)
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Normalize the image data to range [0, 1]
x_train = x_train.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0

# Reshape to include channel dimension (28, 28, 1)
x_train = x_train[..., np.newaxis]
x_test = x_test[..., np.newaxis]

# Convert labels to one-hot encoded format
num_classes = 10
y_train_cat = keras.utils.to_categorical(y_train, num_classes)
y_test_cat = keras.utils.to_categorical(y_test, num_classes)

# Split training data into train and validation sets
from sklearn.model_selection import train_test_split
x_train, x_val, y_train_cat, y_val_cat = train_test_split(x_train, y_train_cat, test_size=0.1, random_state=42)
# 2. Define CNN Model Architecture
# --------------------------------
model = models.Sequential()

# Convolutional Layer 1: Extract Low-Level features
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.MaxPooling2D((2,2)))   # Reduce spatial dimensions

# Convolutional Layer 2
model.add(layers.Conv2D(64, (3, 3), activation='relu'))   # 64 means you're extracting high level features
model.add(layers.MaxPooling2D((2, 2)))

# Flatten the output and feed into Fully Connected Layers
model.add(layers.Flatten())
model.add(layers.Dense(128, activation='relu'))   # Fully connected layer
model.add(layers.Dropout(0.5))  # Dropout for regularization

# Output layer with Softmax for multi-class classification
model.add(layers.Dense(num_classes, activation='softmax'))

# Display the model summary
model.summary()
# 3. Compilation
# --------------
model.compile(optimizer='adam',
             loss='categorical_crossentropy',   # we're using this loss function becasue it's multiclass classification
             metrics=['accuracy'])
# 4. Training the Model
# ---------------------

# Define EarlyStopping to prevent overfitting
early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Train the model
history = model.fit(
    x_train, y_train_cat,
    epochs=15,
    batch_size=128,
    validation_data=(x_val, y_val_cat),
    callbacks=[early_stop]
)
# 5. Testing and Evaluation
# --------------------------
test_loss, test_acc = model.evaluate(x_test, y_test_cat, verbose=2)
print(f"\nTest accuracy: {test_acc:.4f}, Test loss: {test_loss:.4f}")

# Predict on some test images
predictions = model.predict(x_test)
y_pred = np.argmax(predictions, axis=1)

# Display a few predictions
plt.figure(figsize=(10, 4))
for i in range(5):
    plt.subplot(1, 5, i+1)
    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')
    plt.title(f"Pred: {y_pred[i]}\nTrue: {y_test[i]}")
    plt.axis("off")
plt.tight_layout()
plt.show()
# 6. Performance Visualisation
# ----------------------------

# Plot training & validation accuracy/loss
def plot_metrics(history):
    plt.figure(figsize=(12, 5))

    # Accuracy Plot
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Acc')
    plt.plot(history.history['val_accuracy'], label='Val Acc')
    plt.title('Accuracy over Epochs')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    # Loss Plot
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.title('Loss over Epochs')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.tight_layout()
    plt.show()

plot_metrics(history)
# Confusion Matrix and classsification Report
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(10), yticklabels=range(10))
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()
Q.4_Sematic_Segmentation_and_Object_Detection_using_FCN_FRCNN_Mask_R_CNN.ipynb
import torch
import torchvision
from torchvision import transforms
import matplotlib.pyplot as plt
from PIL import Image
# Load pre-trained models for segmentation and detection
fcn_model = torchvision.models.segmentation.fcn_resnet50(pretrained=True)
fcn_model.eval()
faster_rcnn_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
faster_rcnn_model.eval()
# Function to process and show images with FCN segmentation and Faster-RCNN detection
def process_image(image, model_fcn, model_frcnn):
  transform = transforms.Compose([
      transforms.ToTensor(),   # Convert the image to a PyTorch tensor
  ])

  image_tensor = transform(image)

  # FCN Semantic Segmentation
  with torch.no_grad():
    output_fcn = model_fcn(image_tensor.unsqueeze(0))  # Add batch dimension
    output_fcn_predictions = output_fcn['out'].argmax(1).squeeze().cpu().numpy()

  # Faster R-CNN Object Detection
  with torch.no_grad():
    output_frcnn = model_frcnn([image_tensor])

  # Extract boxes and labe;s from Faster R-CNN output
  boxes = output_frcnn[0]['boxes'].cpu().numpy()
  labels = output_frcnn[0]['labels'].cpu().numpy()

  # Plot the original image, FCN segmentation output, and Faster R-CNN detections
  fig, ax = plt.subplots(1, 3, figsize=(15, 5))

  # Original Image
  ax[0].imshow(image)
  ax[0].set_title('Original Image')
  ax[0].axis('off')

  # FCN Segmentation Output
  ax[1].imshow(output_fcn_predictions)
  ax[1].set_title('FCN Segmentation Output')
  ax[1].axis('off')

  # Faster R-CNN Object Detection
  ax[2].imshow(image)
  for box in boxes:
    x_min, y_min, x_max, y_max = box
    rect = plt.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, fill=False, color='red', linewidth=2)
    ax[2].add_patch(rect)
  ax[2].set_title('Faster R-CNN Object Detection')
  ax[2].axis('off')

  plt.tight_layout()
  plt.show()
# Load your images
room_image = Image.open('/road.jpg')
road1_image = Image.open('/road1.jpg')
road2_image = Image.open('/room.jpeg')
# Process each image with the models
process_image(room_image, fcn_model, faster_rcnn_model)
process_image(road1_image, fcn_model, faster_rcnn_model)
process_image(road2_image, fcn_model, faster_rcnn_model)


Q.5_Transfer_Learning_on_the_suitable_dataset_(Cats_and_Dogs_Dataset).ipynb
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import os
import zipfile
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
#Download and extract dataset
url = "https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip"
filename = "cats_and_dogs_filtered.zip"
tf.keras.utils.get_file(filename, url)
with zipfile.ZipFile("cats_and_dogs_filtered.zip", "r") as zip_ref:
    zip_ref.extractall()
#Define data generators
base_dir = "cats_and_dogs_filtered"
train_dir = os.path.join(base_dir, "train")
validation_dir = os.path.join(base_dir, "validation")

train_datagen = ImageDataGenerator(rescale = 1./255,
                                  rotation_range = 20,
                                  width_shift_range = 0.2,
                                  height_shift_range = 0.2,
                                  shear_range = 0.2,
                                  zoom_range = 0.2,
                                  horizontal_flip = True)

validation_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(validation_dir,
                                                        target_size=(150, 150),
                                                        batch_size = 20,
                                                        class_mode = "binary")

validation_generator = validation_datagen.flow_from_directory(validation_dir,
                                                        target_size=(150, 150),
                                                        batch_size = 20,
                                                        class_mode = "binary")
#Load pre_trained VGG16 model
conv_base = VGG16(weights = "imagenet",
                 include_top = False,
                 input_shape=(150, 150, 3))

#Freeze convolutional base layers
conv_base.trainable = False
#Build model on top of the convolution base
model = tf.keras.models.Sequential()
model.add(conv_base)
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(256, activation = "relu"))
model.add(tf.keras.layers.Dropout(0.5))
model.add(tf.keras.layers.Dense(1, activation="sigmoid"))
#Compile Model
model.compile(loss = "binary_crossentropy",
             optimizer = tf.keras.optimizers.RMSprop(learning_rate=2e-5),
             metrics = ["accuracy"])

history = model.fit(train_generator,
                    steps_per_epoch=100,
                    epochs=30,
                    validation_data=validation_generator,
                    validation_steps=50)
# Show sample input and its predicted class
x, y_true = next(validation_generator)
y_pred = model.predict(x)
class_names = ['cat', 'dog' ]
for i in range(len(x)):
    plt.imshow(x[i])
    plt.title(f'Predicted class: {class_names[int(round(y_pred[i][0])) ]}, True class: {class_names[int(y_true[i]) ]}')
    plt.show()

# PLot accuracy and Loss over time
acc = history. history["accuracy"]
val_acc = history.history["val_accuracy"]
loss = history. history["loss"]
val_loss = history.history["val_loss"]

epochs = range(1, len(acc) + 1)

plt.plot(epochs, acc, "bo", label="Training acc")
plt.pllt(epochs, val_acc, "b", label="Validation acc")
plt.title("Trainig and Validation Loss")
plt.legend()

plt.show()
